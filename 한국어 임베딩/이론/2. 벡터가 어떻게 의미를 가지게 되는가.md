# 벡터가 어떻게 의미를 가지게 되는가

## 2.1 자연어 계산과 이해

임베딩을 만드는 세 가지 철학

| 구분        | bag  of words 가정                               | 언어 모델                       | 분포 가정                     |
| ----------- | ------------------------------------------------ | ------------------------------- | ----------------------------- |
| 내용        | 어떤 단어가 __많이__ 쓰였는가                    | 단어가 어떤 __순서__로 쓰였는가 | 어떤 단어가 __같이__ 쓰였는가 |
| 대표 통계량 | TF-IDF, Counter, Hashing                         | -                               | PMI                           |
| 대표 모델   | Deep Averaging Network<br />(단어의 순서 고려 X) | ELMo, GPT                       | Word2Vec                      |

- 통계 기반 언어 모델
  - 언어 모델: 단어 시퀀스에 확률을 부여하는 모델
  - __n-gram__ : n개의 단어
  - __최대우도추정법__ : 조건부 확률 정의 활용(전체 확률이 0이 될 수 있음):arrow_right: __n-gram 모델__
  - 문제: 