# BERT

- 양방향 학습
- 관련 논문: https://arxiv.org/pdf/1810.04805.pdf

---

## 학습 과정

1. 마스크 언어 모델(MLM)
   - 단어를 마스킹하여 마스킹 된 부분 예측
2. 다음 문장 예측(NSP)

위의 2가지를 학습하여 다른 학습(ex.감정분석)에 활용한다.
