# 머신러닝: 의사결정트리

- 입력데이터가 까다롭지 않다
- **과적합**에 대한 보완이 필요하다
  - 학습 정확도는 높지만, 예측 데이터 정확도는 낮은 경우를 뜻함
- 출발점을 `Root노드`라고 하고, 마지막의 `Leaf노드`의 `class`가 해당 데이터의 예측 `class`가 된다.

:grey_exclamation:**매 노드에서 불순도를 낮출 수 있는 가장 중요한 Feature와 기준값을 찾는다.**

:arrow_right: 불순도=0 또는 미리 설정한 멈춤 기준에 해당하는 경우 나무 생성 중단



`gini`: 불순도(불순도가 낮아지도록 분기)

`sample`: 노드에 도달한 데이터 갯수

`value`: 데이터 구조(갯수)

`class`: 다수결로 결정



## CODE

1. 의사결정나무 준비

```python
# 대여건수가 500건이 넘는지 아닌지
# 의사결정나무
from sklearn import tree
X = X_train
y = y_train
dTree = tree.DecisionTreeClassifier()
dTreeModel = dTree.fit(X, y)
dTreeModel
```

2. 의사결정나무 생성

```python
# 사전에 graphviz, pydotplus 설치해줘야 된다.
from sklearn.tree import export_graphviz
import pydotplus
from IPython.display import Image

dot_data = export_graphviz(dTreeModel, out_file=None,
                         feature_names=['cum_precipitation', 'humidity', 'temp', 'wind'],
                         class_names=('Y', 'N'), filled=True, rounded=True, special_characters=True)
graph = pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png())
```

3. 예측값 보기

```python
dTreeModel.predict(X_test)
#-------------------------
array([1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1],
      dtype=int64)
```

4. 정확도 측정

```python
from sklearn.metrics import accuracy_score

y_pred = dTreeModel.predict(X_test)
print('Accuracy: %.2f' %accuracy_score(y_test,y_pred))
```

5. 리포트로 확인

```python
y_pred = dTreeModel.predict(X_test)
print(classification_report(y_test, y_pred))
#=====================================================
              precision    recall  f1-score   support

           0       0.86      0.67      0.75         9
           1       0.79      0.92      0.85        12

    accuracy                           0.81        21
   macro avg       0.82      0.79      0.80        21
weighted avg       0.82      0.81      0.80        21
```

